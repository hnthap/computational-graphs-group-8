{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graphs &mdash; Ví dụ bằng `torch`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhóm 8 xin giới thiệu tới các bạn cách xây dựng đồ thị tính toán bằng PyTorch.\n",
    "\n",
    "Dưới đây là hai cách khác nhau để xây dựng một đồ thị tính toán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn cần download và install `torch` để sử dụng.\n",
    "\n",
    "Bạn cũng có thể không download thư viện mà dùng Google Colab để mở và chạy notebook này, tuy nhiên lúc này cần kết nối Internet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational Graph được xây dựng và thực thi trong PyTorch như thế nào ?\n",
    "- https://pytorch.org/blog/computational-graphs-constructed-in-pytorch/\n",
    "- https://pytorch.org/blog/how-computational-graphs-are-executed-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Data type\n",
    "dtype = torch.float\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Current device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print('Current device name:', torch.cuda.get_device_name())\n",
    "    print('CUDA device count:', torch.cuda.device_count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ví dụ 1 : Tự định nghĩa một hàm số"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta định nghĩa một hàm số $f$ theo các bước sau :\n",
    "- Tạo class cho $f$. Class này kế thừa `torch.autograd.Function`.\n",
    "- Ghi đè hàm `forward`. Hàm này định nghĩa cách tính giá trị của nút áp dụng $f$ từ (các) đầu vào.\n",
    "- Ghi đè hàm `backward`. Hàm này định nghĩa cách tính đạo hàm của nút đích cuối cùng ứng với từng đầu vào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        result = x.exp()\n",
    "        ctx.save_for_backward(result)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        result, = ctx.saved_tensors\n",
    "        return grad_outputs * result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trên đây là một cách định nghĩa hàm số $f(x) = e^{x}$.\n",
    "\n",
    "Trong hàm `forward`, ta tính giá trị của hàm ứng với $x$ (dòng `result = x.exp()`).\n",
    "\n",
    "Trong hàm `backward`, ta tính đạo hàm của nút đích ứng với $x$. Vì\n",
    "\n",
    "$$\\frac{\\partial{f(x)}}{\\partial{x}} = e^{x}$$\n",
    "\n",
    "nên ta có thể định nghĩa `backward` như trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor(0.5000, requires_grad=True)\n",
      "f(x) = tensor(1.6487, grad_fn=<ExpBackward>)\n",
      "df(x)/dx = tensor(1.6487)\n"
     ]
    }
   ],
   "source": [
    "# Let x = 0.5\n",
    "x = torch.tensor(0.5, dtype=dtype, device=device, requires_grad=True)\n",
    "print('x =', x)\n",
    "\n",
    "# Compute y = f(x)\n",
    "y = Exp.apply(x)\n",
    "print('f(x) =', y)\n",
    "\n",
    "# Compute dy/dx\n",
    "x.grad = None\n",
    "y.backward()\n",
    "print('df(x)/dx =', x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong ví dụ trên, $x$ là một tensor mang giá trị vô hướng. \n",
    "\n",
    "Thông số `requires_grad=True` thông báo rằng ta cần tính đạo hàm ứng với tensor này. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ví dụ 2 : Sử dụng các hàm mặc định"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xét\n",
    "$$f(x, A) = x^\\top A\\;x$$\n",
    "trong đó $x$ là vector dọc, $A$ là ma trận hai chiều. Giả sử các phép toán luôn có nghĩa.\n",
    "\n",
    "Trong ví dụ này, ta có thể tính toán giá trị và đạo hàm theo cách đơn giản hơn nhiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "tensor([[0.],\n",
      "        [5.]], grad_fn=<ReshapeAliasBackward0>)\n",
      "A\n",
      "tensor([[0., 1.],\n",
      "        [1., 2.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Let x = [[0],\n",
    "#          [5]]\n",
    "# and A = [[0  1]\n",
    "#          [1  2]]\n",
    "\n",
    "x = torch.tensor([0, 5], dtype=dtype, device=device, requires_grad=True).reshape((-1, 1))\n",
    "A = torch.tensor([[0, 1], [1, 2]], dtype=dtype, device=device, requires_grad=True)\n",
    "print('x')\n",
    "print(x)\n",
    "print('A')\n",
    "print(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên ta tạo các tensor cho $x$ và $A$ (chú ý `shape` của vector). Gán cho chúng một giá trị."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = f(x, A) = 50.0\n"
     ]
    }
   ],
   "source": [
    "# Compute y = f(x, A)\n",
    "\n",
    "y = x.T.mm(A).mm(x)\n",
    "print('y = f(x, A) =', y.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tính $y = f(x, A)$, ta chỉ cần gán `y = x.T.mm(A).mm(x)`. Lúc này hàm `forward` mặc định được gọi.\n",
    "\n",
    "Biết rằng `mm` là hàm tính phép nhân giữa hai ma trận, `x.T` là ma trận chuyển vị của `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx\n",
      "tensor([[10.],\n",
      "        [20.]])\n",
      "dy/dA\n",
      "tensor([[ 0.,  0.],\n",
      "        [ 0., 25.]])\n"
     ]
    }
   ],
   "source": [
    "# Compute dy/dA, dy/dx\n",
    "\n",
    "for var in (x, A):\n",
    "    var.retain_grad()\n",
    "    var.grad = None\n",
    "y.backward(retain_graph=True)\n",
    "print('dy/dx')\n",
    "print(x.grad)\n",
    "print('dy/dA')\n",
    "print(A.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tính đạo hàm của `y` ứng với `x` và `A`, ta gán thông số `grad` của mỗi đầu vào bằng `None` và gọi `y.backward()` để tính đạo hàm. Đạo hàm khi này được lưu thẳng vào thông số `grad` của mỗi đầu vào.\n",
    "\n",
    "Hàm `retain_grad()` của tensor thông báo rằng tensor đó cần được tính đạo hàm, dù có thể không phải nút lá.\n",
    "\n",
    "Các định nghĩa về đạo hàm của các phép toán được áp dụng (nhân và chuyển vị ma trận) đã được định nghĩa sẵn bởi PyTorch, nên khác với ví dụ 1, ta không cần định nghĩa lại nữa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
